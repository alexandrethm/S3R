{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "import numpy\n",
    "import pickle\n",
    "from scipy import ndimage as ndimage\n",
    "from sklearn.utils import shuffle\n",
    "import itertools\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath='/home/gu/PycharmProjects/SHREC2017/pour_les_etudiants/shrec_data.pckl'):\n",
    "    \"\"\"\n",
    "    Returns hand gesture sequences (X) and their associated labels (Y).\n",
    "    Each sequence has two different labels.\n",
    "    The first label Y describes the gesture class out of 14 possible gestures (e.g. swiping your hand to the right).\n",
    "    The second label Y describes the gesture class out of 28 possible gestures (e.g. swiping your hand to the right with your index pointed, or not pointed).\n",
    "    \"\"\"\n",
    "    file = open(filepath, 'rb')\n",
    "    data = pickle.load(file)\n",
    "    file.close()\n",
    "    return data['x_train'], data['x_test'], data['y_train_14'], data['y_train_28'], data['y_test_14'], data['y_test_28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_sequences_length(x_train, x_test, final_length=100):\n",
    "    \"\"\"\n",
    "    Resize the time series by interpolating them to the same length\n",
    "    \"\"\"\n",
    "    # python2 important note: redefine the classic division operator / by importing it from the __future__ module\n",
    "    x_train = numpy.array([\n",
    "        numpy.array([\n",
    "            ndimage.zoom(x_i.T[j], final_length / len(x_i), mode='reflect') for j in range(numpy.size(x_i, 1))\n",
    "        ]).T\n",
    "        for x_i\n",
    "        in x_train\n",
    "    ])\n",
    "    x_test = numpy.array([\n",
    "        numpy.array([\n",
    "            ndimage.zoom(x_i.T[j], final_length / len(x_i), mode='reflect') for j in\n",
    "            range(numpy.size(x_i, 1))\n",
    "        ]).T\n",
    "        for x_i\n",
    "        in x_test\n",
    "    ])\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_dataset(x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28):\n",
    "    \"\"\"Shuffle the train/test data consistently.\"\"\"\n",
    "    # note: add random_state=0 for reproducibility\n",
    "    x_train, y_train_14, y_train_28 = shuffle(x_train, y_train_14, y_train_28)\n",
    "    x_test, y_test_14, y_test_28 = shuffle(x_test, y_test_14, y_test_28)\n",
    "    return x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_data(x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28):\n",
    "    \"\"\"\n",
    "    Preprocess the data as you want.\n",
    "    \"\"\"\n",
    "    x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28 = shuffle_dataset(x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28)\n",
    "    x_train, x_test = resize_sequences_length(x_train, x_test, final_length=100)\n",
    "    \n",
    "    return x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_pytorch_tensors(x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28):\n",
    "    \n",
    "    y_train_14 = numpy.array(y_train_14)\n",
    "    y_train_28 = numpy.array(y_train_28)\n",
    "    y_test_14 = numpy.array(y_test_14)\n",
    "    y_test_28 = numpy.array(y_test_28)\n",
    "\n",
    "    # Remove 1 to all classes items (1-14 => 0-13 and 1-28 => 0-27)\n",
    "    y_train_14 = y_train_14 - 1\n",
    "    y_train_28 = y_train_28 - 1\n",
    "    y_test_14 = y_test_14 - 1\n",
    "    y_test_28 = y_test_28 - 1\n",
    "\n",
    "    x_train = torch.from_numpy(x_train)\n",
    "    x_test = torch.from_numpy(x_test)\n",
    "    y_train_14 = torch.from_numpy(y_train_14)\n",
    "    y_train_28 = torch.from_numpy(y_train_28)\n",
    "    y_test_14 = torch.from_numpy(y_test_14)\n",
    "    y_test_28 = torch.from_numpy(y_test_28)\n",
    "\n",
    "    x_train = x_train.type(torch.FloatTensor)\n",
    "    x_test = x_test.type(torch.FloatTensor)\n",
    "    y_train_14 = y_train_14.type(torch.LongTensor)\n",
    "    y_test_14 = y_test_14.type(torch.LongTensor)\n",
    "    y_train_28 = y_train_28.type(torch.LongTensor)\n",
    "    y_test_28 = y_test_28.type(torch.LongTensor)\n",
    "    \n",
    "    return x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    [Devineau et al., 2018] Deep Learning for Hand Gesture Recognition on Skeletal Data\n",
    "    \n",
    "    This model computes a succession of 3x [convolutions and pooling] independently on each of the 66 sequence channels.\n",
    "    \n",
    "    Each of these computations are actually done at two different resolutions, that are later merged by concatenation\n",
    "    with the (pooled) original sequence channel.\n",
    "    \n",
    "    Finally, a multi-layer perceptron merges all of the processed channels and outputs a classification.\n",
    "    \n",
    "    In short:\n",
    "    \n",
    "        1. input --> split into 66 channels\n",
    "        \n",
    "        2.1. channel_i --> 3x [conv/pool/dropout] low_resolution_i\n",
    "        2.2. channel_i --> 3x [conv/pool/dropout] high_resolution_i\n",
    "        2.3. channel_i --> pooled_i\n",
    "        \n",
    "        2.4. low_resolution_i, high_resolution_i, pooled_i --> output_channel_i\n",
    "        \n",
    "        3. MLP(66x [output_channel_i]) ---> classification\n",
    "    \n",
    "    \n",
    "    Note: \"joint\" is a synonym of \"channel\".\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_joints=66, num_classes=14):\n",
    "        \n",
    "        \"\"\"\n",
    "        Instantiation of the parameters.\n",
    "        \n",
    "        Params:\n",
    "            :param num_joints: \n",
    "            :param num_classes: \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.dropout_probability = 0.2\n",
    "\n",
    "        # Layers ----------------------------------------------\n",
    "        self.all_conv_high_res_first = torch.nn.ModuleList([torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=1, out_channels=8, kernel_size=7, padding=3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(2)\n",
    "        )])\n",
    "        self.all_conv_high_res_then = torch.nn.ModuleList([torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=8, out_channels=4, kernel_size=7, padding=3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(2),\n",
    "\n",
    "            torch.nn.Conv1d(in_channels=4, out_channels=4, kernel_size=7, padding=3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=self.dropout_probability),\n",
    "            torch.nn.AvgPool1d(2)\n",
    "        ) for joint in range(num_joints + 1)])\n",
    "\n",
    "        self.all_conv_low_first = torch.nn.ModuleList([torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(2)\n",
    "        )])\n",
    "        self.all_conv_low_res_then = torch.nn.ModuleList([torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=8, out_channels=4, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(2),\n",
    "\n",
    "            torch.nn.Conv1d(in_channels=4, out_channels=4, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=self.dropout_probability),\n",
    "            torch.nn.AvgPool1d(2)\n",
    "        ) for joint in range(num_joints + 1)])\n",
    "\n",
    "        self.all_residual = torch.nn.ModuleList([torch.nn.Sequential(\n",
    "            torch.nn.AvgPool1d(2),\n",
    "            torch.nn.AvgPool1d(2),\n",
    "            torch.nn.AvgPool1d(2)\n",
    "        ) for joint in range(num_joints + 1)])\n",
    "\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=9 * 66 * 12, out_features=1936),  # <-- depends of the sequences lengths (cf. below)\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=1936, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "        # Initialization --------------------------------------\n",
    "        # Xavier init\n",
    "        for module in itertools.chain(self.all_conv_high_res_first, self.all_conv_high_res_then, self.all_conv_low_first, self.all_conv_low_res_then, self.all_residual):\n",
    "            for layer in module:\n",
    "                if layer.__class__.__name__ == \"Conv1d\":\n",
    "                    torch.nn.init.xavier_uniform(layer.weight, gain=torch.nn.init.calculate_gain('relu'))\n",
    "                    torch.nn.init.constant(layer.bias, 0.1)\n",
    "\n",
    "        for layer in self.fc:\n",
    "            if layer.__class__.__name__ == \"Linear\":\n",
    "                torch.nn.init.xavier_uniform(layer.weight, gain=torch.nn.init.calculate_gain('relu'))\n",
    "                torch.nn.init.constant(layer.bias, 0.1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        This function performs the actual computations of the network for a forward pass.\n",
    "\n",
    "        Params:\n",
    "            :param input: A tensor of gestures. Its shape is (batch_size x temporal_duration x nb_channels)\n",
    "        \"\"\"\n",
    "\n",
    "        # BS, TS, SS\n",
    "        _, _, spatial_steps = input.size()\n",
    "\n",
    "        # Work on each joint separately\n",
    "        every_joint_out_all_time = []\n",
    "\n",
    "        for joint in range(0, spatial_steps):\n",
    "            input_joint = input[:, :, joint]\n",
    "\n",
    "            # Add a dummy (spatial) dimension for the time convolutions\n",
    "            # Conv1D format : (batch_size, num_feature_maps, length_of_seq)\n",
    "            input_joint = input_joint.unsqueeze(1)\n",
    "\n",
    "            # note: the first conv/pool weigths are shared between all channels\n",
    "            high = self.all_conv_high_res_first[0](input_joint)\n",
    "            high = self.all_conv_high_res_then[joint](high)\n",
    "\n",
    "            low = self.all_conv_low_first[0](input_joint)\n",
    "            low = self.all_conv_low_res_then[joint](low)\n",
    "\n",
    "            orig = self.all_residual[joint](input_joint)\n",
    "\n",
    "            # Time convolutions are concatenated along the feature maps axis\n",
    "            output_joint = torch.cat([\n",
    "                high,\n",
    "                low,\n",
    "                orig\n",
    "            ], dim=1)\n",
    "            every_joint_out_all_time.append(output_joint)\n",
    "\n",
    "        # Concatenate along the feature maps axis\n",
    "        every_joint_out_all_time_cat = torch.cat(every_joint_out_all_time, dim=1)\n",
    "        \n",
    "        # Flatten for the Linear layers\n",
    "        every_joint_out_all_time_cat = every_joint_out_all_time_cat.view(-1, 9 * 66 * 12)  # <-- depends of the sequences lengths\n",
    "        # 9 * 66 * 12 = numpy.product(list(every_joint_out_all_time_cat.size()))/32, where 32 is the batch size\n",
    "\n",
    "        # Fully-Connected Layers\n",
    "        output = self.fc(every_joint_out_all_time_cat)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------\n",
    "# Misc.\n",
    "# -------------\n",
    "\n",
    "\n",
    "def batch(tensor, batch_size=32):\n",
    "    \"\"\"Return a list of (mini) batches\"\"\"\n",
    "    tensor_list = []\n",
    "    length = tensor.shape[0]\n",
    "    i = 0\n",
    "    while True:\n",
    "        if (i + 1) * batch_size >= length:\n",
    "            tensor_list.append(tensor[i * batch_size: length])\n",
    "            return tensor_list\n",
    "        tensor_list.append(tensor[i * batch_size: (i + 1) * batch_size])\n",
    "        i += 1\n",
    "\n",
    "\n",
    "def time_since(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '{:02d}m {:02d}s'.format(int(m), int(s))\n",
    "\n",
    "\n",
    "def get_accuracy(model, x_tensor, y_tensor_real):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        :param model: a **pytorch** model\n",
    "        :param x_tensor:  a **pytorch** tensor/Variable\n",
    "        :param y_tensor_real:  a **pytorch** tensor/Variable\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predicted = model(torch.autograd.Variable(x_tensor))\n",
    "    predicted = predicted.max(dim=1)[1]\n",
    "    s = (predicted.data == y_tensor_real).sum()\n",
    "    s = 1.0 * s / y_tensor_real.size()[0]\n",
    "    model.train()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gu/miniconda2/lib/python2.7/site-packages/scipy/ndimage/interpolation.py:600: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n  \"the returned array has changed.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# -------------\n",
    "# Data\n",
    "# -------------\n",
    "\n",
    "# Load the dataset\n",
    "x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28 = load_data()\n",
    "\n",
    "# Shuffle sequences and resize sequences\n",
    "x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28 = preprocess_data(x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28)\n",
    "\n",
    "# Convert to pytorch variables\n",
    "x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28 = convert_to_pytorch_tensors(x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------\n",
    "# Network instantiation\n",
    "# -------------\n",
    "net = Net(num_classes=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------\n",
    "# 3. Loss function & Optimizer\n",
    "# -----------------------------------------------------\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------\n",
    "# Training\n",
    "# -------------\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer,\n",
    "          x_train, y_train, x_test, y_test,\n",
    "          num_epochs=5):\n",
    "    \n",
    "    # Prepare all mini-batches\n",
    "    x_train_batches = batch(x_train)\n",
    "    y_train_batches = batch(y_train)\n",
    "    \n",
    "    # Training starting time\n",
    "    start = time.time()\n",
    "\n",
    "    print('[INFO] Started to train the model.')\n",
    "    \n",
    "    for ep in range(num_epochs):\n",
    "\n",
    "        # Ensure we're still in training mode\n",
    "        model.train()\n",
    "\n",
    "        current_loss = 0.0\n",
    "\n",
    "        for idx_batch, train_batches in enumerate(zip(x_train_batches, y_train_batches)):\n",
    "\n",
    "            # get a mini-batch of sequences\n",
    "            x_train_batch, y_train_batch = train_batches\n",
    "            x_train_batch, y_train_batch = torch.autograd.Variable(x_train_batch), torch.autograd.Variable(y_train_batch)\n",
    "\n",
    "            # zero the gradient parameters\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            outputs = model(x_train_batch)\n",
    "\n",
    "            # backward + optimize\n",
    "            # backward\n",
    "            loss = criterion(outputs, y_train_batch)\n",
    "            loss.backward()\n",
    "            # optimize\n",
    "            optimizer.step()\n",
    "            # for an easy access\n",
    "            current_loss += loss.data[0]\n",
    "            \n",
    "        print('Epoch #{:03d} | Time elapsed : {} | Loss : {:.4e} | Accuracy_train : {:.4e} | Accuracy_test : {:.4e}'.format(\n",
    "                ep + 1, time_since(start), current_loss, get_accuracy(model, x_train, y_train), get_accuracy(model, x_test, y_test)))\n",
    "\n",
    "    print('[INFO] Finished training the model. Total time : {}.'.format(time_since(start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Started to train the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #001 | Time elapsed : 00m 24s | Loss : 4.5208e+02 | Accuracy_train : 2.8776e-01 | Accuracy_test : 2.4253e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #002 | Time elapsed : 00m 55s | Loss : 9.8361e+01 | Accuracy_train : 5.5510e-01 | Accuracy_test : 5.2091e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #003 | Time elapsed : 01m 27s | Loss : 6.7919e+01 | Accuracy_train : 6.6327e-01 | Accuracy_test : 5.8901e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #004 | Time elapsed : 01m 57s | Loss : 5.3127e+01 | Accuracy_train : 7.2245e-01 | Accuracy_test : 6.4875e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #005 | Time elapsed : 02m 27s | Loss : 4.3585e+01 | Accuracy_train : 7.3827e-01 | Accuracy_test : 6.4516e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #006 | Time elapsed : 02m 57s | Loss : 3.7026e+01 | Accuracy_train : 7.7194e-01 | Accuracy_test : 6.7384e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #007 | Time elapsed : 03m 26s | Loss : 3.3076e+01 | Accuracy_train : 8.0102e-01 | Accuracy_test : 6.9056e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #008 | Time elapsed : 03m 58s | Loss : 2.9102e+01 | Accuracy_train : 8.2143e-01 | Accuracy_test : 7.0729e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #009 | Time elapsed : 04m 29s | Loss : 2.5687e+01 | Accuracy_train : 8.5612e-01 | Accuracy_test : 7.3596e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #010 | Time elapsed : 05m 00s | Loss : 2.3646e+01 | Accuracy_train : 8.9184e-01 | Accuracy_test : 8.0645e-01\n"
     ]
    }ÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿ