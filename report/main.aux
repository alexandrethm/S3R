\relax 
\providecommand{\transparent@use}[1]{}
\providecommand\hyper@newdestlabel[2]{}
\catcode `:\active 
\catcode `;\active 
\catcode `!\active 
\catcode `?\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{intro-autonomous-driving}
\citation{coupete:hal-01306482}
\citation{real-time-human-pose-recognition-in-parts-from-a-single-depth-image}
\citation{simon2017hand-openpose}
\citation{dhg-non-deep-approach}
\citation{Maghoumi-deep-gru}
\citation{Goodfellow-et-al-2016}
\citation{Devineau}
\citation{Bai2018-tcn}
\babel@aux{french}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}What kind of gesture recognition ?}{1}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Existing approaches, ours}{1}{subsection.1.2}\protected@file@percent }
\citation{Devineau}
\citation{dhg-non-deep-approach}
\citation{dhg-non-deep-approach}
\citation{desmedt:shrec}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textit  {The full skeleton returned by an Intel Real Sense Depth camera}\relax }}{2}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:hand-skeleton}{{1}{2}{\textit {The full skeleton returned by an Intel Real Sense Depth camera}\relax }{figure.caption.1}{}}
\newlabel{fig:hand-skeleton@cref}{{[figure][1][]1}{[1][2][]2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Work}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Network architecture}{2}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Input data}{2}{subsubsection.2.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textit  {Evolution of the data sequences $s_i$ for a Swipe X gesture, before resizing}\relax }}{3}{figure.caption.2}\protected@file@percent }
\newlabel{fig:temporal-sequences}{{2}{3}{\textit {Evolution of the data sequences $s_i$ for a Swipe X gesture, before resizing}\relax }{figure.caption.2}{}}
\newlabel{fig:temporal-sequences@cref}{{[figure][2][]2}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Preprocessing module}{3}{subsubsection.2.1.2}\protected@file@percent }
\newlabel{section:preprocessing-module}{{2.1.2}{3}{Preprocessing module}{subsubsection.2.1.2}{}}
\newlabel{section:preprocessing-module@cref}{{[subsubsection][2][2,1]2.1.2}{[1][3][]3}}
\@writefile{toc}{\contentsline {paragraph}{A linear module applying spatial combinations}{3}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{No preprocessing module}{3}{section*.4}\protected@file@percent }
\citation{Devineau}
\citation{Devineau}
\citation{He_2016-residual}
\citation{Devineau}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textit  {Architecture of a regular convolution block. Kernel size can be $k=3$ or $k=7$ depending on the branch, and the \emph  {groups} parameter allows the 1D Conv block to process inputs independantly}\relax }}{4}{figure.caption.6}\protected@file@percent }
\newlabel{fig:regular-conv-block-architecture}{{3}{4}{\textit {Architecture of a regular convolution block. Kernel size can be $k=3$ or $k=7$ depending on the branch, and the \emph {groups} parameter allows the 1D Conv block to process inputs independantly}\relax }{figure.caption.6}{}}
\newlabel{fig:regular-conv-block-architecture@cref}{{[figure][3][]3}{[1][4][]4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Convolutional module}{4}{subsubsection.2.1.3}\protected@file@percent }
\newlabel{section:convolutional-module}{{2.1.3}{4}{Convolutional module}{subsubsection.2.1.3}{}}
\newlabel{section:convolutional-module@cref}{{[subsubsection][3][2,1]2.1.3}{[1][3][]4}}
\@writefile{toc}{\contentsline {paragraph}{A regular 1D Convolutional network}{4}{section*.5}\protected@file@percent }
\citation{salimans2016weight}
\citation{Bai2018-tcn}
\newlabel{fig:regular-conv-layer}{{4a}{5}{\textit {A regular 1D convolution layer}\relax }{figure.caption.7}{}}
\newlabel{fig:regular-conv-layer@cref}{{[subfigure][1][4]4a}{[1][4][]5}}
\newlabel{sub@fig:regular-conv-layer}{{a}{5}{\textit {A regular 1D convolution layer}\relax }{figure.caption.7}{}}
\newlabel{sub@fig:regular-conv-layer@cref}{{[subfigure][1][4]4a}{[1][4][]5}}
\newlabel{fig:regular-conv-layer-with-groups}{{4b}{5}{\textit {A regular 1D convolution layer, with $groups=2$ (instead of 1, by default). Half of the inputs are convolved to produce half of the outputs, independantly}\relax }{figure.caption.7}{}}
\newlabel{fig:regular-conv-layer-with-groups@cref}{{[subfigure][2][4]4b}{[1][4][]5}}
\newlabel{sub@fig:regular-conv-layer-with-groups}{{b}{5}{\textit {A regular 1D convolution layer, with $groups=2$ (instead of 1, by default). Half of the inputs are convolved to produce half of the outputs, independantly}\relax }{figure.caption.7}{}}
\newlabel{sub@fig:regular-conv-layer-with-groups@cref}{{[subfigure][2][4]4b}{[1][4][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textit  {Illustration of regular 1D convolutions}\relax }}{5}{figure.caption.7}\protected@file@percent }
\newlabel{section:tcn}{{2.1.3}{5}{A Temporal Convolutional network (\emph {TCN})}{section*.8}{}}
\newlabel{section:tcn@cref}{{[subsubsection][3][2,1]2.1.3}{[1][5][]5}}
\@writefile{toc}{\contentsline {paragraph}{A Temporal Convolutional network (\emph  {TCN})}{5}{section*.8}\protected@file@percent }
\citation{Bai2018-tcn}
\citation{kingma2014adam}
\citation{Ruder2016-gradient-descent-algos-overview}
\citation{xavier-init}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Schematic illustration of the MLP used for classification. There are $L_{out} \times C_{out} \times 2$ inputs and as many outputs as the number of classes (14 or 28 for the DHG dataset). There can be one or more hidden layer, each of size $n_{hidden}^{(i)}$.\relax }}{6}{figure.caption.9}\protected@file@percent }
\newlabel{fig:mlp-classification-module}{{5}{6}{Schematic illustration of the MLP used for classification. There are $L_{out} \times C_{out} \times 2$ inputs and as many outputs as the number of classes (14 or 28 for the DHG dataset). There can be one or more hidden layer, each of size $n_{hidden}^{(i)}$.\relax }{figure.caption.9}{}}
\newlabel{fig:mlp-classification-module@cref}{{[figure][5][]5}{[1][6][]6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}Classification module}{6}{subsubsection.2.1.4}\protected@file@percent }
\newlabel{section:classification-module}{{2.1.4}{6}{Classification module}{subsubsection.2.1.4}{}}
\newlabel{section:classification-module@cref}{{[subsubsection][4][2,1]2.1.4}{[1][6][]6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Hyperparameters}{6}{subsection.2.2}\protected@file@percent }
\citation{keskar2016largebatch}
\citation{He_2015-prelu}
\citation{ramach2017-swish}
\newlabel{section:batch-size}{{2.2}{7}{Hyperparameters}{subsection.2.2}{}}
\newlabel{section:batch-size@cref}{{[subsection][2][2]2.2}{[1][7][]7}}
\newlabel{section:act-fct}{{2.2}{7}{Hyperparameters}{subsection.2.2}{}}
\newlabel{section:act-fct@cref}{{[subsection][2][2]2.2}{[1][7][]7}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{7}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Implementation}{7}{subsection.3.1}\protected@file@percent }
\citation{Devineau}
\newlabel{fig:heatmap-conv-layers-nb-size}{{6a}{8}{Mean accuracy of different convolution architectures on the validation set (using 3-fold cross-validation)\relax }{figure.caption.11}{}}
\newlabel{fig:heatmap-conv-layers-nb-size@cref}{{[subfigure][1][6]6a}{[1][8][]8}}
\newlabel{sub@fig:heatmap-conv-layers-nb-size}{{a}{8}{Mean accuracy of different convolution architectures on the validation set (using 3-fold cross-validation)\relax }{figure.caption.11}{}}
\newlabel{sub@fig:heatmap-conv-layers-nb-size@cref}{{[subfigure][1][6]6a}{[1][8][]8}}
\newlabel{fig:scatter-conv-layers-nb-size}{{6b}{8}{Mean accuracy on the validation set (y-axis) and the training set (x-axis). Models in the bottom right part of the graph are more likely to overfit on the training set.\relax }{figure.caption.11}{}}
\newlabel{fig:scatter-conv-layers-nb-size@cref}{{[subfigure][2][6]6b}{[1][8][]8}}
\newlabel{sub@fig:scatter-conv-layers-nb-size}{{b}{8}{Mean accuracy on the validation set (y-axis) and the training set (x-axis). Models in the bottom right part of the graph are more likely to overfit on the training set.\relax }{figure.caption.11}{}}
\newlabel{sub@fig:scatter-conv-layers-nb-size@cref}{{[subfigure][2][6]6b}{[1][8][]8}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Influence of the number and the size of convolution layers on accuracy.\relax }}{8}{figure.caption.11}\protected@file@percent }
\newlabel{fig:conv-size}{{6}{8}{Influence of the number and the size of convolution layers on accuracy.\relax }{figure.caption.11}{}}
\newlabel{fig:conv-size@cref}{{[figure][6][]6}{[1][8][]8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Convolutional module}{8}{subsection.3.2}\protected@file@percent }
\newlabel{section:conv-size}{{3.2}{8}{How to size the network ?}{section*.10}{}}
\newlabel{section:conv-size@cref}{{[subsection][2][3]3.2}{[1][8][]8}}
\@writefile{toc}{\contentsline {paragraph}{How to size the network ?}{8}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{The \emph  {groups} parameter}{8}{section*.12}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Influence of the $groups$ parameter on accuracy. Each one of the $C_{out}$ convolutions sees only $\frac  {66}{groups}$ input sequences. $groups=1$ is a classical convolution layer, $groups=66$ means that input sequences are processed independantly.   The average score on the 3 splits of the cross-validation is taken, and the blue bars represent the 95\% confidence interval.\relax }}{9}{figure.caption.13}\protected@file@percent }
\newlabel{fig:groups-parameter}{{7}{9}{Influence of the $groups$ parameter on accuracy. Each one of the $C_{out}$ convolutions sees only $\frac {66}{groups}$ input sequences. $groups=1$ is a classical convolution layer, $groups=66$ means that input sequences are processed independantly. \\ The average score on the 3 splits of the cross-validation is taken, and the blue bars represent the 95\% confidence interval.\relax }{figure.caption.13}{}}
\newlabel{fig:groups-parameter@cref}{{[figure][7][]7}{[1][8][]9}}
\@writefile{toc}{\contentsline {paragraph}{What about TCNs ?}{9}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Preprocessing module}{9}{subsection.3.3}\protected@file@percent }
\newlabel{fig:tcn_nb_layers}{{8a}{10}{Here the number of channels per convolution layer is set to $C_{out}=300$ and we change the number of layers\relax }{figure.caption.15}{}}
\newlabel{fig:tcn_nb_layers@cref}{{[subfigure][1][8]8a}{[1][9][]10}}
\newlabel{sub@fig:tcn_nb_layers}{{a}{10}{Here the number of channels per convolution layer is set to $C_{out}=300$ and we change the number of layers\relax }{figure.caption.15}{}}
\newlabel{sub@fig:tcn_nb_layers@cref}{{[subfigure][1][8]8a}{[1][9][]10}}
\newlabel{fig:tcn_nb_channels}{{8b}{10}{Here the number of layers is set to $d=5$ and we change the number of output channels per layer\relax }{figure.caption.15}{}}
\newlabel{fig:tcn_nb_channels@cref}{{[subfigure][2][8]8b}{[1][9][]10}}
\newlabel{sub@fig:tcn_nb_channels}{{b}{10}{Here the number of layers is set to $d=5$ and we change the number of output channels per layer\relax }{figure.caption.15}{}}
\newlabel{sub@fig:tcn_nb_channels@cref}{{[subfigure][2][8]8b}{[1][9][]10}}
\newlabel{fig:tcn_kernel_size}{{8c}{10}{Here we have 5 layers with $C_{out}=300$ output channels, and we change the kernel size (previously set to 3)\relax }{figure.caption.15}{}}
\newlabel{fig:tcn_kernel_size@cref}{{[subfigure][3][8]8c}{[1][9][]10}}
\newlabel{sub@fig:tcn_kernel_size}{{c}{10}{Here we have 5 layers with $C_{out}=300$ output channels, and we change the kernel size (previously set to 3)\relax }{figure.caption.15}{}}
\newlabel{sub@fig:tcn_kernel_size@cref}{{[subfigure][3][8]8c}{[1][9][]10}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Experiments on TCNs architectures\relax }}{10}{figure.caption.15}\protected@file@percent }
\newlabel{fig:tcn}{{8}{10}{Experiments on TCNs architectures\relax }{figure.caption.15}{}}
\newlabel{fig:tcn@cref}{{[figure][8][]8}{[1][9][]10}}
\citation{kingma2014adam}
\citation{He_2015-prelu}
\citation{ramach2017-swish}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Accuracy obtained with various sizes of the linear preprocessing module (blue curve). The red line is the reference architecture, without a preprocessing module.\relax }}{11}{figure.caption.16}\protected@file@percent }
\newlabel{fig:preprocessing}{{9}{11}{Accuracy obtained with various sizes of the linear preprocessing module (blue curve). The red line is the reference architecture, without a preprocessing module.\relax }{figure.caption.16}{}}
\newlabel{fig:preprocessing@cref}{{[figure][9][]9}{[1][9][]11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Classification module}{11}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Other hyperparameters}{11}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Batch size}{11}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Learning rate}{11}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Activation function}{11}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Dropout}{11}{section*.24}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Experiments on the size and the depth of the MLP we use for classification\relax }}{12}{figure.caption.17}\protected@file@percent }
\newlabel{fig:fc_layers}{{10}{12}{Experiments on the size and the depth of the MLP we use for classification\relax }{figure.caption.17}{}}
\newlabel{fig:fc_layers@cref}{{[figure][10][]10}{[1][11][]12}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Experiments on the batch size\relax }}{12}{figure.caption.19}\protected@file@percent }
\newlabel{fig:batch-size}{{11}{12}{Experiments on the batch size\relax }{figure.caption.19}{}}
\newlabel{fig:batch-size@cref}{{[figure][11][]11}{[1][11][]12}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Experiments on the learning rate\relax }}{13}{figure.caption.21}\protected@file@percent }
\newlabel{fig:learning-rate}{{12}{13}{Experiments on the learning rate\relax }{figure.caption.21}{}}
\newlabel{fig:learning-rate@cref}{{[figure][12][]12}{[1][11][]13}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Comparison of different activation functions\relax }}{13}{figure.caption.23}\protected@file@percent }
\newlabel{fig:act-fct}{{13}{13}{Comparison of different activation functions\relax }{figure.caption.23}{}}
\newlabel{fig:act-fct@cref}{{[figure][13][]13}{[1][11][]13}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Experiments on the dropout\relax }}{13}{figure.caption.25}\protected@file@percent }
\newlabel{fig:dropout}{{14}{13}{Experiments on the dropout\relax }{figure.caption.25}{}}
\newlabel{fig:dropout@cref}{{[figure][14][]14}{[1][11][]13}}
\citation{Maghoumi-deep-gru}
\citation{STA-Res-TCN}
\citation{desmedt:shrec}
\citation{Devineau}
\citation{STA-Res-TCN}
\citation{Maghoumi-deep-gru}
\citation{Devineau}
\citation{STA-Res-TCN}
\bibstyle{plain}
\bibdata{sources}
\bibcite{Bai2018-tcn}{1}
\bibcite{coupete:hal-01306482}{2}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparaisons of accuracy (\%) on the SHREC17 DHG dataset\relax }}{14}{table.caption.26}\protected@file@percent }
\newlabel{tab:results}{{1}{14}{Comparaisons of accuracy (\%) on the SHREC17 DHG dataset\relax }{table.caption.26}{}}
\newlabel{tab:results@cref}{{[table][1][]1}{[1][14][]14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Results on the DHG dataset}{14}{subsection.3.6}\protected@file@percent }
\newlabel{section:results}{{3.6}{14}{Results on the DHG dataset}{subsection.3.6}{}}
\newlabel{section:results@cref}{{[subsection][6][3]3.6}{[1][11][]14}}
\@writefile{toc}{\contentsline {paragraph}{Regular CNN}{14}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{TCN}{14}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{14}{section.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Confusion matrix of our regular CNN model on the DHG-14/28 test dataset. In the 14 gesture classes case we do not make a difference between using 1 finger and the whole hand, whereas we do in the other case.\relax }}{15}{figure.caption.28}\protected@file@percent }
\newlabel{fig:confusion-matrix}{{15}{15}{Confusion matrix of our regular CNN model on the DHG-14/28 test dataset. In the 14 gesture classes case we do not make a difference between using 1 finger and the whole hand, whereas we do in the other case.\relax }{figure.caption.28}{}}
\newlabel{fig:confusion-matrix@cref}{{[figure][15][]15}{[1][14][]15}}
\bibcite{dhg-non-deep-approach}{3}
\bibcite{desmedt:shrec}{4}
\bibcite{intro-autonomous-driving}{5}
\bibcite{Devineau}{6}
\bibcite{xavier-init}{7}
\bibcite{Goodfellow-et-al-2016}{8}
\bibcite{He_2015-prelu}{9}
\bibcite{He_2016-residual}{10}
\bibcite{STA-Res-TCN}{11}
\bibcite{keskar2016largebatch}{12}
\bibcite{kingma2014adam}{13}
\bibcite{Maghoumi-deep-gru}{14}
\bibcite{ramach2017-swish}{15}
\bibcite{Ruder2016-gradient-descent-algos-overview}{16}
\bibcite{salimans2016weight}{17}
\bibcite{real-time-human-pose-recognition-in-parts-from-a-single-depth-image}{18}
\bibcite{simon2017hand-openpose}{19}
