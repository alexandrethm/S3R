
@inproceedings{intro-autonomous-driving,
author = {Deng, Qiwen and Tian, Renran and Chen, Yaobin and Li, Kang},
year = {2018},
month = {06},
pages = {1293-1298},
title = {Skeleton model based behavior recognition for pedestrians and cyclists from vehicle sce ne camera},
doi = {10.1109/IVS.2018.8500359}
}
@inproceedings{coupete:hal-01306482,
  TITLE = {{Recognition of Technical Gestures for Human-Robot Collaboration in Factories}},
  AUTHOR = {Coupet{\'e}, Eva and Moutarde, Fabien and Manitsaris, Sotiris and Hugues, Olivier},
  URL = {https://hal.archives-ouvertes.fr/hal-01306482},
  BOOKTITLE = {{The Ninth International Conference on Advances in Computer-Human Interactions}},
  ADDRESS = {Venise, Italy},
  YEAR = {2016},
  MONTH = Apr,
  KEYWORDS = {--Human-robot collaboration ; Industrial application ; Assembly line ; Gestures recognition ; Depth camera},
  PDF = {https://hal.archives-ouvertes.fr/hal-01306482/file/achi_2016_13_30_20164.pdf},
  HAL_ID = {hal-01306482},
  HAL_VERSION = {v1},
}
@Inproceedings{real-time-human-pose-recognition-in-parts-from-a-single-depth-image,
author = {Shotton, Jamie and Fitzgibbon, Andrew and  and Kipman, Alex and Finocchio, Mark and  and Sharp, Toby},
title = {Real-Time Human Pose Recognition in Parts from a Single Depth Image},
year = {2011},
month = {June},
abstract = {
We propose a new method to quickly and accurately predict 3D positions of body joints from a single depth image, using no temporal information. We take an object recognition approach, designing an intermediate body parts representation that maps the difficult pose estimation problem into a simpler per-pixel classification problem. Our large and highly varied training dataset allows the classifier to estimate body parts invariant to pose, body shape, clothing, etc. Finally we generate confidence-scored 3D proposals of several body joints by reprojecting the classification result and finding local modes.
The system runs at 200 frames per second on consumer hardware. Our evaluation shows high accuracy on both synthetic and real test sets, and investigates the effect of several training parameters. We achieve state of the art accuracy in our comparison with related work and demonstrate improved generalization over exact whole-skeleton nearest neighbor matching.
},
publisher = {IEEE},
url = {https://www.microsoft.com/en-us/research/publication/real-time-human-pose-recognition-in-parts-from-a-single-depth-image/},
edition = {CVPR},
note = {Best Paper Award},
}
@inproceedings{simon2017hand-openpose,
  author = {Tomas Simon and Hanbyul Joo and Iain Matthews and Yaser Sheikh},
  booktitle = {CVPR},
  title = {Hand Keypoint Detection in Single Images using Multiview Bootstrapping},
  year = {2017}
}
@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    url={http://www.deeplearningbook.org},
    year={2016}
}@inproceedings{desmedt:shrec,
  TITLE = {{SHREC'17 Track: 3D Hand Gesture Recognition Using a Depth and Skeletal Dataset}},
  AUTHOR = {De Smedt, Quentin and Wannous, Hazem and Vandeborre, Jean-Philippe and Guerry, Joris and Le Saux, Bertrand and Filliat, David},
  URL = {https://hal.archives-ouvertes.fr/hal-01563505},
  BOOKTITLE = {{3DOR - 10th Eurographics Workshop on 3D Object Retrieval}},
  ADDRESS = {Lyon, France},
  EDITOR = {I. Pratikakis and F. Dupont and M. Ovsjanikov},
  PAGES = {1-6},
  YEAR = {2017},
  MONTH = Apr,
  DOI = {10.2312/3dor.20171049},
  KEYWORDS = {machine learning ; computer graphic ; Gesture recognition},
  PDF = {https://hal.archives-ouvertes.fr/hal-01563505/file/17-EG3DOR-SHREC-Hand-Gesture-DeSmedt.pdf},
  HAL_ID = {hal-01563505},
  HAL_VERSION = {v1},
}
@inbook{STA-Res-TCN,
author = {Hou, Jingxuan and Wang, Guijin and Chen, Xinghao and Xue, Jing-Hao and Zhu, Rui and Yang, Huazhong},
year = {2019},
month = {01},
pages = {273-286},
title = {Spatial-Temporal Attention Res-TCN for Skeleton-Based Dynamic Hand Gesture Recognition: Munich, Germany, September 8-14, 2018, Proceedings, Part VI},
isbn = {978-3-030-11023-9},
doi = {10.1007/978-3-030-11024-6_18}
}
@INPROCEEDINGS{dhg-non-deep-approach,
author={Q. {De Smedt} and H. {Wannous} and J. {Vandeborre}},
booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
title={Skeleton-Based Dynamic Hand Gesture Recognition},
year={2016},
volume={},
number={},
pages={1206-1214},
abstract={In this paper, a new skeleton-based approach is proposed for 3D hand gesture recognition. Specifically, we exploit the geometric shape of the hand to extract an effective descriptor from hand skeleton connected joints returned by the Intel RealSense depth camera. Each descriptor is then encoded by a Fisher Vector representation obtained using a Gaussian Mixture Model. A multi-level representation of Fisher Vectors and other skeleton-based geometric features is guaranteed by a temporal pyramid to obtain the final feature vector, used later to achieve the classification by a linear SVM classifier. The proposed approach is evaluated on a challenging hand gesture dataset containing 14 gestures, performed by 20 participants performing the same gesture with two different numbers of fingers. Experimental results show that our skeleton-based approach consistently achieves superior performance over a depth-based approach.},
keywords={computational geometry;gesture recognition;image classification;image sensors;shape recognition;support vector machines;skeleton-based dynamic hand gesture recognition;3D hand gesture recognition;geometric shape;Intel RealSense depth camera;Gaussian mixture model;Fisher vectors;linear SVM classifier;Gesture recognition;Three-dimensional displays;Skeleton;Shape;Cameras;Sensors;Databases},
doi={10.1109/CVPRW.2016.153},
ISSN={2160-7516},
month={June},}
@article{Bai2018-tcn,
abstract = {For most deep learning practitioners, sequence modeling is synonymous with recurrent networks. Yet recent results indicate that convolutional architectures can outperform recurrent networks on tasks such as audio synthesis and machine translation. Given a new sequence modeling task or dataset, which architecture should one use? We conduct a systematic evaluation of generic convolutional and recurrent architectures for sequence modeling. The models are evaluated across a broad range of standard tasks that are commonly used to benchmark recurrent networks. Our results indicate that a simple convolutional architecture outperforms canonical recurrent networks such as LSTMs across a diverse range of tasks and datasets, while demonstrating longer effective memory. We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks. To assist related work, we have made code available at http://github.com/locuslab/TCN .},
archivePrefix = {arXiv},
arxivId = {1803.01271},
author = {Bai, Shaojie and Kolter, J. Zico and Koltun, Vladlen},
doi = {10.1016/S0925-5273(03)00047-1},
eprint = {1803.01271},
file = {:Users/alexandre/Library/Application Support/Mendeley Desktop/Downloaded/Bai, Kolter, Koltun - 2018 - An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling.pdf:pdf},
isbn = {0146-0404},
issn = {09255273},
mendeley-groups = {Gesture recognition,S3R bibtex},
pmid = {21168153},
title = {{An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling}},
year = {2018}
}
@techreport{Maghoumi-deep-gru,
abstract = {We introduce DeepGRU, a deep learning based gesture and action recognizer. Our method is deceptively simple , yet versatile for various application scenarios. Using only raw pose and vector data, DeepGRU can achieve high recognition accuracy results regardless of the dataset size, the number of training samples or the choice of the input device. At the heart of our method lies a set of stacked GRUs, two fully connected layers and a global attention model. We demonstrate that in the absence of powerful hardware, and using only the CPU, our method can still be trained in a short period of time, making it suitable for rapid prototyping and development scenarios. We evaluate our proposed method on 7 publicly available datasets, spanning over a broad range of interactions as well as dataset sizes. In most cases, we outperform the state-of-the-art pose-based methods. We achieve a recognition accuracy of 84.9{\%} and 92.3{\%} on cross-subject and cross-view tests of the NTU RGB+D dataset respectively, and also 100{\%} recognition accuracy on the UT-Kinect dataset.},
author = {Maghoumi, Mehran and Laviola, Joseph J},
file = {:Users/alexandre/Library/Application Support/Mendeley Desktop/Downloaded/Maghoumi, Laviola - Unknown - DeepGRU Deep Gesture Recognition Utility.pdf:pdf},
mendeley-groups = {Gesture recognition/Recurrent models,S3R bibtex},
title = {{DeepGRU: Deep Gesture Recognition Utility}}
}
@techreport{Devineau,
abstract = {In this paper, we study a convolutional neural network we recently introduced in [9], intended to recognize 3D hand gestures via multivariate time series classification. The Convolutional Neural Network (CNN) we proposed processes sequences of hand-skeletal joints' positions using parallel convolutions. We justify the model's architecture and investigate its performance on hand gesture sequence classification tasks. Our model only uses hand-skeletal data and no depth image. Experimental results show that our approach achieves a state-of-the-art performance on a challenging dataset (DHG dataset from the SHREC 2017 3D Shape Retrieval Contest).Our model achieves a 91.28{\%} classification accuracy for the 14 gesture classes case and an 84.35{\%} classification accuracy for the 28 gesture classes case.},
author = {Devineau, G and Xi, W and Moutarde, F and Yang, J},
file = {:Users/alexandre/Library/Application Support/Mendeley Desktop/Downloaded/Devineau et al. - Unknown - Convolutional Neural Networks for Multivariate Time Series Classification using both Inter-{\&} Intra-Channel P.pdf:pdf},
mendeley-groups = {Gesture recognition/Convolutional models,S3R bibtex},
title = {{Convolutional Neural Networks for Multivariate Time Series Classification using both Inter-{\&} Intra-Channel Parallel Convolutions}},
url = {https://hal-mines-paristech.archives-ouvertes.fr/hal-01888862}
}
@article{Kipf2016,
abstract = {We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.},
archivePrefix = {arXiv},
arxivId = {1609.02907},
author = {Kipf, Thomas N. and Welling, Max},
eprint = {1609.02907},
file = {:Users/alexandre/Library/Application Support/Mendeley Desktop/Downloaded/Kipf, Welling - 2016 - Semi-Supervised Classification with Graph Convolutional Networks.pdf:pdf},
mendeley-groups = {S3R bibtex},
month = {sep},
title = {{Semi-Supervised Classification with Graph Convolutional Networks}},
url = {http://arxiv.org/abs/1609.02907},
year = {2016}
}
@article{He_2016-residual,
   title={Deep Residual Learning for Image Recognition},
   ISBN={9781467388511},
   url={http://dx.doi.org/10.1109/CVPR.2016.90},
   DOI={10.1109/cvpr.2016.90},
   journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
   publisher={IEEE},
   author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
   year={2016},
   month={Jun}
}
@misc{salimans2016weight,
    title={Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks},
    author={Tim Salimans and Diederik P. Kingma},
    year={2016},
    eprint={1602.07868},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@article{Ruder2016-gradient-descent-algos-overview,
  title={An overview of gradient descent optimization algorithms},
  author={Sebastian Ruder},
  journal={CoRR},
  year={2016},
  volume={abs/1609.04747}
}
@misc{kingma2014adam,
    title={Adam: A Method for Stochastic Optimization},
    author={Diederik P. Kingma and Jimmy Ba},
    year={2014},
    eprint={1412.6980},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@misc{keskar2016largebatch,
    title={On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima},
    author={Nitish Shirish Keskar and Dheevatsa Mudigere and Jorge Nocedal and Mikhail Smelyanskiy and Ping Tak Peter Tang},
    year={2016},
    eprint={1609.04836},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@article{He_2015-prelu,
   title={Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},
   ISBN={9781467383912},
   url={http://dx.doi.org/10.1109/ICCV.2015.123},
   DOI={10.1109/iccv.2015.123},
   journal={2015 IEEE International Conference on Computer Vision (ICCV)},
   publisher={IEEE},
   author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
   year={2015},
   month={Dec}
}
@misc{ramach2017-swish,
    title={Searching for Activation Functions},
    author={Prajit Ramachandran and Barret Zoph and Quoc V. Le},
    year={2017},
    eprint={1710.05941},
    archivePrefix={arXiv},
    primaryClass={cs.NE}
}
@article{xavier-init,
author = {Glorot, Xavier and Bengio, Y},
year = {2010},
month = {01},
pages = {249-256},
title = {Understanding the difficulty of training deep feedforward neural networks},
volume = {9},
journal = {Journal of Machine Learning Research - Proceedings Track}
}